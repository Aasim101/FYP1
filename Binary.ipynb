{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff32c72-3207-45c1-924c-a25e728940ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/fast/miniconda3/lib/python3.12/site-packages (from opencv-python) (2.2.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a8b1ba-7151-4c65-8561-0add952f1a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 19:37:15.404357: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-20 19:37:15.412177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745159835.421162  879995 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745159835.423817  879995 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745159835.430824  879995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745159835.430833  879995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745159835.430835  879995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745159835.430836  879995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-20 19:37:15.433306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9977cb-84df-45b0-8bf9-5a190d1bb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def convert_dicom_to_png(dicom_path, output_path):\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    img = ds.pixel_array.astype(float)\n",
    "    # Normalize the image to 0-255\n",
    "    img = (np.maximum(img, 0) / img.max()) * 255.0\n",
    "    img = np.uint8(img)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "# Convert all DICOM files in the directory\n",
    "dicom_dir = 'normal_brain_data/'\n",
    "output_dir = 'normal_brain_images/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(dicom_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.dcm'):\n",
    "            dicom_path = os.path.join(root, file)\n",
    "            output_path = os.path.join(output_dir, file.replace('.dcm', '.png'))\n",
    "            convert_dicom_to_png(dicom_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf70d1a-b257-400f-bf6f-f4658520517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get file paths\n",
    "tumor_images = glob.glob('tumor_data/*.png')\n",
    "normal_images = glob.glob('normal_brain_images/*.png')\n",
    "\n",
    "# Assign labels: 1 for tumor, 0 for normal\n",
    "file_paths = tumor_images + normal_images\n",
    "labels = [1] * len(tumor_images) + [0] * len(normal_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718cb5ec-7586-4208-b929-f6212ddda9a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train, X_val, y_train, y_val = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e0c7c7-8fdd-4319-83a2-bd1ea2c28075",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No images found in TUMOR_DIR (/media/fast/New Volume/FAST/Asim/archive(1)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData) or HEALTHY_DIR (/path/to/Healthy_Dataset).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Check that we found at least tumor or healthy images\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tumor_imgs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m healthy_imgs:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in TUMOR_DIR (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTUMOR_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) or HEALTHY_DIR (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHEALTHY_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Create labels\u001b[39;00m\n\u001b[32m     81\u001b[39m labels_tumor   = [\u001b[32m1\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(tumor_imgs)\n",
      "\u001b[31mValueError\u001b[39m: No images found in TUMOR_DIR (/media/fast/New Volume/FAST/Asim/archive(1)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData) or HEALTHY_DIR (/path/to/Healthy_Dataset)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# -------------------\n",
    "# Configuration (update paths accordingly)\n",
    "# -------------------\n",
    "IMG_HEIGHT, IMG_WIDTH = 300, 300\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS_HEAD = 10\n",
    "EPOCHS_FINE = 10\n",
    "# Directory containing BraTS tumor cases\n",
    "TUMOR_DIR = '/media/fast/New Volume/FAST/Asim/archive(1)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "# Directory containing healthy control MRIs (same modalities as BraTS)\n",
    "HEALTHY_DIR = '/path/to/Healthy_Dataset'\n",
    "\n",
    "# -------------------\n",
    "# Helper functions\n",
    "# -------------------\n",
    "def load_pair(img_path, mask_path):\n",
    "    # Load image volume\n",
    "    img_vol = nib.load(img_path).get_fdata().astype(np.float32)\n",
    "    # Determine mask volume: zeros for healthy\n",
    "    if mask_path is None or mask_path == 'None':\n",
    "        mask_vol = np.zeros_like(img_vol, dtype=bool)\n",
    "    else:\n",
    "        mask_vol = nib.load(mask_path).get_fdata() > 0\n",
    "\n",
    "    # Select central slice\n",
    "    slice_idx = img_vol.shape[2] // 2\n",
    "    slice_img  = img_vol[:, :, slice_idx]\n",
    "    slice_mask = mask_vol[:, :, slice_idx].astype(np.float32)\n",
    "\n",
    "    # Apply mask\n",
    "    roi = slice_img * slice_mask\n",
    "\n",
    "    # Normalize intensities to [0,1]\n",
    "    if roi.max() > 0:\n",
    "        roi = (roi - roi.min()) / (roi.max() - roi.min())\n",
    "\n",
    "    # Resize to model input size\n",
    "    roi_resized = cv2.resize(roi, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    # Stack to 3 channels for EfficientNet\n",
    "    img_3ch = np.stack([roi_resized] * 3, axis=-1)\n",
    "    return img_3ch\n",
    "\n",
    "@tf.function\n",
    "def tf_load_pair(img_path, mask_path, label):\n",
    "    img = tf.py_function(\n",
    "        func=lambda x, y: load_pair(x.decode('utf-8'), None if y.decode('utf-8')=='None' else y.decode('utf-8')),\n",
    "        inp=[img_path, mask_path], Tout=tf.float32)\n",
    "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    return img, label\n",
    "\n",
    "# -------------------\n",
    "# Gather file paths and labels\n",
    "# -------------------\n",
    "# Tumor-positive cases\n",
    "tumor_imgs  = glob.glob(os.path.join(TUMOR_DIR, 'BraTS20_Training_*', '*_t1ce.nii.gz'))\n",
    "tumor_masks = glob.glob(os.path.join(TUMOR_DIR, 'BraTS20_Training_*', '*_seg.nii.gz'))\n",
    "# Healthy controls (if any)\n",
    "healthy_imgs = glob.glob(os.path.join(HEALTHY_DIR, '*.nii.gz'))\n",
    "healthy_masks = [None] * len(healthy_imgs)\n",
    "\n",
    "# Check that we found at least tumor or healthy images\n",
    "if not tumor_imgs and not healthy_imgs:\n",
    "    raise ValueError(f\"No images found in TUMOR_DIR ({TUMOR_DIR}) or HEALTHY_DIR ({HEALTHY_DIR}).\")\n",
    "\n",
    "# Create labels\n",
    "labels_tumor   = [1] * len(tumor_imgs)\n",
    "labels_healthy = [0] * len(healthy_imgs)\n",
    "\n",
    "# Combine lists\n",
    "img_list   = tumor_imgs + healthy_imgs\n",
    "mask_list  = tumor_masks + healthy_masks\n",
    "label_list = labels_tumor + labels_healthy\n",
    "\n",
    "# Determine stratification: only if both classes present\n",
    "unique_labels = set(label_list)\n",
    "stratify_labels = label_list if len(unique_labels) > 1 else None\n",
    "if stratify_labels is None:\n",
    "    print(\"Warning: Only one class present; proceeding without stratified split.\")\n",
    "\n",
    "# Split into train/validation\n",
    "X_img_train, X_img_val, X_mask_train, X_mask_val, y_train, y_val = train_test_split(\n",
    "    img_list, mask_list, label_list,\n",
    "    test_size=0.2,\n",
    "    stratify=stratify_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# Build tf.data datasets\n",
    "# -------------------\n",
    "def make_dataset(img_paths, mask_paths, labels, batch_size, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(labels), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(\n",
    "        lambda i, m, l: tf_load_pair(i, tf.convert_to_tensor(str(m), dtype=tf.string), l),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dataset(X_img_train, X_mask_train, y_train, BATCH_SIZE)\n",
    "val_ds   = make_dataset(X_img_val,   X_mask_val,   y_val,   BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# -------------------\n",
    "# Build and compile model\n",
    "# -------------------\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False,\n",
    "                            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, preds)\n",
    "model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# -------------------\n",
    "# Train classifier head\n",
    "# -------------------\n",
    "print('Training classification head...')\n",
    "history_head = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD)\n",
    "\n",
    "# -------------------\n",
    "# Fine-tune full model\n",
    "# -------------------\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('Fine-tuning entire model...')\n",
    "history_finetune = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FINE)\n",
    "\n",
    "# -------------------\n",
    "# Evaluation\n",
    "# -------------------\n",
    "# Gather predictions\n",
    "y_true, y_pred, y_prob = [], [], []\n",
    "for imgs, labs in val_ds:\n",
    "    probs = model.predict(imgs)\n",
    "    preds = (probs >= 0.5).astype(int).flatten()\n",
    "    y_pred.extend(preds)\n",
    "    y_prob.extend(probs.flatten())\n",
    "    y_true.extend(labs.numpy())\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('Classification Report:\\n', classification_report(y_true, y_pred))\n",
    "if len(set(y_true)) == 2:\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.figure(); plt.plot(fpr, tpr, label=f'AUC={roc_auc:.3f}'); plt.plot([0,1],[0,1],'--'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308325c5-50d2-448e-ae01-78fc05fa3125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
